{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Criminal Case Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Contents:\n",
    "- Background\n",
    "- Webscraping Lawnet\n",
    "- Webscraping Singapore Statutes\n",
    "- [Natural Language Processing](#4.-Natural-Language-Processing) **(In this notebook)**\n",
    "- Search Function\n",
    "- Flask and Google App Engine\n",
    "- Conclusion and Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "For the Natural Language Processing of the datasets, I will use the datasets which I created previously. These will be run through the processor to obtain the final datasets which will form the basis of my database.  \n",
    "\n",
    "The datasets that I will use are as follows:- \n",
    "\n",
    "* subordinatecourt.csv\n",
    "* subordinatecourt_compiled.csv \n",
    "* statecourt.csv \n",
    "* statecourt_compiled.csv\n",
    "* statutes_crimes.csv\n",
    "\n",
    "The datasets that I will create are as follows:-\n",
    "\n",
    "* database.csv\n",
    "* database_temp.csv  \n",
    "\n",
    "\n",
    "The information extracted will be presented in the database in the following format:  \n",
    "\n",
    "|Name|Type|Dataset|Description|\n",
    "|:---|:---|:---|:---|\n",
    "|**case_name**|*object*|database.csv|Case name|\n",
    "|**tribunal/court**|*object*|database.csv|Court of judgment|\n",
    "|**decision_date**|*object*|database.csv|Decision date of the judgment|\n",
    "|**possible_offences**|*object*|database.csv|Possible offences discussed in the judgment|\n",
    "|**possible_statutes**|*object*|database.csv|Possible statutes discussed in the judgment|\n",
    "|**citations**|*object*|database.csv|Other cases discussed or cited in the judgment|\n",
    "|**mitigation_discussed**|*object*|database.csv|Whether mitigating circumstances were discussed in the judgment|\n",
    "|**aggravation_discussed**|*object*|database.csv|Whether aggravating circumstances were discussed in the judgment|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will be exploring the use of Natural Language Processing (NLP) to identify key information from each judgment to create a database of information for the judgments that I have archived.  \n",
    "\n",
    "This database can be used as a starting point for legal research by quickly giving statistical summaries of recent cases, and the case links on Lawnet.  \n",
    "\n",
    "The information I am looking to extract:  \n",
    "\n",
    "* Case name  \n",
    "* Court of judgment  \n",
    "* Decision date  \n",
    "* Possible offences discussed in the judgment \n",
    "* Possible statutes discussed in the judgment  \n",
    "* Cases cited in the judgment  \n",
    "* Whether mitigating circumstances were discussed  \n",
    "* Whether aggravating circumstances were discussed  \n",
    "\n",
    "The above information may help a lawyer to quickly decide whether the judgment is relevant to his/her case and whether it is worth researching on, further, it will also help him/her to quickly identify further cases cited to expand the research.  \n",
    "To achieve this, there are two possible methods of information extraction which I am aware of:  \n",
    "1. Rule-based Information Extraction (RBIE)  \n",
    "2. Named Entity Recognition (NER)  \n",
    "\n",
    "In RBIE, a set of rules (or multiple sets of rules) is used for the identification of patterns which match the rules in order to extract the information. It is a more transparent method as the rules are clearly defined, and it can be maintained easily.\n",
    "\n",
    "In NER, unstructured text is processed through machine learning to identify named entities and classify them into predefined categories such as for the purposes of this project, `case_name` or `statutes`. NER can be advantageous as it uses machine learning to train a model that can identify the named entities within the unstructured text. It can result in a more efficient process that is able to better capture and classify named entities which may be missed by rules. However, as most machine learning models, it may end up overfit or underfit, and maintaining it would require retraining the model.  \n",
    "For my project, I chose to work with RBIE given the limited amount of time I have. I did not want to use a pre-trained NER model as a 'plug-and-play' method, and training an NER model from scratch to extract the information I want would require the manual tagging of the named entities for the training data. Given the sheer number of words in each judgment, and the limitation of data that I have (less than 200 judgments in total), I was not confident that I had sufficient data and time to train the NER model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Judgment Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, I created a custom class `Database` which has methods for the following:  \n",
    "1. Calculate the number of rows for each `court` class in the final database, and in their respective court judgment databases  \n",
    "2. Identify the number of new rows to set a start and end point for the NLP  \n",
    "3. Extract the various information from the judgment based on sets of rules   \n",
    "4. Update and save the final database with the information from new judgments  \n",
    "\n",
    "![example of a judgment](../images/judgment.png)  \n",
    "\n",
    "An example of a judgment from Lawnet [1]:  \n",
    "- The blue box indicates the `case_name`  \n",
    "- The red box indicates the `decision_date` and `tribunal/court`  \n",
    "- The green boxes show examples of `possible_statutes` which consists of section numbers and statute names  \n",
    "- The orange boxes show examples of other case `citations`  \n",
    "\n",
    "By going through the html code of the judgment, I was able to pick out various html tags where the information required can be found. Thus the basis of my RBIE rule sets was formed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Database class creation  \n",
    "\n",
    "The first step once again is to create the class Database, and initialize it.  \n",
    "\n",
    "<details> \n",
    "    <summary> <b> Click here for code </b></summary>\n",
    "    \n",
    "```python\n",
    "# Create the Database class\n",
    "class Database:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the class and loads the datasets.\n",
    "        \"\"\"\n",
    "        # Load the .csv files as pandas dataframes\n",
    "        self.supremecourt_df = pd.read_csv('../data/supremecourt_compiled.csv')\n",
    "        self.subordinatecourt_df = pd.read_csv('../data/subordinatecourt_compiled.csv')\n",
    "        self.database_df = pd.read_csv('../data/database.csv')\n",
    "        self.statutes_df = pd.read_csv('../data/statutes_crimes.csv')\n",
    "        \n",
    "```  \n",
    "</details>  \n",
    "\n",
    "During initialization, the datasets to be used are loaded as pandas dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Number of rows  \n",
    "\n",
    "As mentioned above, I created a private method which calculates the number of rows in the two court datasets `supremecourt_compiled.csv` and `subordinatecourt_compiled.csv`, as well as the difference in number of rows for each of these court categories in the final database `database.csv`.  \n",
    "\n",
    "The purpose of this method is to find out if there are any new entries to be processed (determined by a difference in number of rows between the court datasets and the final database) and to find the start and end indices for the NLP.  \n",
    "\n",
    "<details>\n",
    "    <summary> <b> Click here for code </b></summary>\n",
    "    \n",
    "```python\n",
    "    def __get_num_rows(self):\n",
    "        \"\"\"\n",
    "        Calculates the number of rows there are in each dataset.\n",
    "        \"\"\"\n",
    "        # Find the number of rows in each court's dataframe\n",
    "        self.__supremecourt_rows = len(self.supremecourt_df)\n",
    "        self.__subordinatecourt_rows = len(self.subordinatecourt_df)\n",
    "        \n",
    "        # Compare the number of rows for each court in the database to find out how many new rows there are\n",
    "        self.__new_supremecourt_rows = self.__supremecourt_rows - len(self.database_df[self.database_df['court_tag'] == 'supreme'])\n",
    "        self.__new_subordinatecourt_rows = self.__subordinatecourt_rows - len(self.database_df[self.database_df['court_tag'] == 'subordinate'])\n",
    "   \n",
    "    \n",
    "``` \n",
    "</details>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 Case name  \n",
    "\n",
    "As mentioned above, based on the html tags, I was able to identify that the `case_name` was nested within the `h2` tag. Hence the method to extract the case name searches only within this tag. It takes the info as text and returns a dictionary for the `case_name`.  \n",
    "\n",
    "Further, it creates a temporary variable for the `temp_case_name` without its legal citation notation for example \"[2021] SGCA 3\" in the image above. This will be used to remove the `case_name` of the judgment being processed from the other case `citations` down the pipeline.  \n",
    "\n",
    "<details>\n",
    "    <summary> <b> Click here for code </b></summary>\n",
    "    \n",
    "```python\n",
    "    def __get_case_name(self):\n",
    "        \"\"\"\n",
    "        Takes out the case name from the judgment\n",
    "        \"\"\"\n",
    "        # Search for the case name in the judgment\n",
    "        self.__case_name = {'case_name': self.__search_results.find('h2').text.strip()}\n",
    "        \n",
    "        # Create a temp variable for the case name without the case citation notation by looking for patterns of Capitalized words with name terms which are followed by v and further capitalized words with name terms as these suggest that it is a case name\n",
    "        self.__temp_case_name = re.search('(([A-Z][a-z]*)(([A-Z][a-z]*)|(s\\/o| |bte|bin|and|another|anr|binti|de|the|for|other|matters))* v (([A-Z][a-z]*)|(s\\/o| |bte|bin|and|another|anr|binti|de|the|for|other|matters))*(?=|))', str(self.__case_name)).group(0).strip()\n",
    "        \n",
    "        # Return case name as a dictionary\n",
    "        return self.__case_name   \n",
    "    \n",
    "``` \n",
    "</details>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4 Court name and Decision Date  \n",
    "\n",
    "The `tribunal/court` and `decision_date` information are found within the `info-table id` of the html. Hence their methods simply search within this id to find match the patterns `Tribunal/Court :` and `Decision Date :` to capture their information.  \n",
    "\n",
    "The information is theen split into two parts by the colon `:` to return the final information dictionaries.  \n",
    "\n",
    "<details>\n",
    "    <summary> <b> Click here for __get_court code </b></summary>\n",
    "    \n",
    "```python\n",
    "    def __get_court(self):\n",
    "        \"\"\"\n",
    "        Takes out the court name from the judgment\n",
    "        \"\"\"\n",
    "        # Search for the info table in the html\n",
    "        self.__temp_results1 = self.__search_results.find('table', {'id': 'info-table'})\n",
    "        \n",
    "        # Picks out the court info in the search results as string\n",
    "        self.__temp_court = re.search('Tribunal/Court : (\\w* )*(?=Coram)', self.__temp_results1.text).group(0).strip()\n",
    "        \n",
    "        # Split the court info string to the key and value\n",
    "        self.__temp_list = self.__temp_court.split(\" : \")\n",
    "        \n",
    "        # Set court info in a dictionary\n",
    "        self.__court = {str.lower(self.__temp_list[0]): self.__temp_list[1]}\n",
    "        \n",
    "        # Return court info as a dictionary\n",
    "        return self.__court   \n",
    "    \n",
    "``` \n",
    "</details>  \n",
    "\n",
    "<details>\n",
    "    <summary> <b> Click here for __get_date code </b></summary>\n",
    "    \n",
    "```python\n",
    "    def __get_date(self):\n",
    "        \"\"\"\n",
    "        Takes out the court name from the judgment\n",
    "        \"\"\"\n",
    "        # Search for the info table in the html\n",
    "        self.__temp_results1 = self.__search_results.find('table', {'id': 'info-table'})\n",
    "        \n",
    "        # Picks out the decision date in the search results as string\n",
    "        self.__temp_date = re.search('Decision Date : (\\w* )*(?=Tribunal)', self.__temp_results1.text).group(0).strip()\n",
    "        \n",
    "        # Split the decision date to the key and value\n",
    "        self.__temp_list = self.__temp_date.split(\" : \")\n",
    "        \n",
    "        # Set decision date in a dictionary\n",
    "        self.__decision_date = {'decision_date': self.__temp_list[1]}\n",
    "        \n",
    "        # Return decision date as a dictionary\n",
    "        return self.__decision_date   \n",
    "    \n",
    "``` \n",
    "</details>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.5 Possible Statutes and Offences  \n",
    "\n",
    "Identifying the possible statutes and offences required a more complex method. They could either be found within the judgment's header with html tags `span` within `p class:'txt-body'` or within the judgment text itself.  \n",
    "\n",
    "The pattern to identify possible statutes is that they will follow one of the following formats:  \n",
    "* `Section` `space` `digits` where section can be plural and is case insensitive, and there is at least 1 digit (e.g. Section 33)  \n",
    "* `space` `S` `space` `digits` where s is preceded by a space and can be plural and is case insensitive, and there is at least 1 digit (e.g. s 33)  \n",
    "Followed by the name of the statute:  \n",
    "* `Word` `space` `of (optional)``Act` where there can be more than one word which may have `of` in between, followed by Act in title case (e.g. Misuse of Drugs Act)  \n",
    "* `Word` `space` `of (optional)``Code` where there can be more than one word which may have `of` in between, followed by Code in title case (e.g. Penal Code)\n",
    "\n",
    "This results in a `regex` pattern of `( [Ss](ection|)(s|) \\d+)` to find the sections and `((([A-Z][a-z]*)|(Corruption, Drug Trafficking and Other Serious Crimes \\(Confiscation of Benefits\\)|and|of| )){2,}(Act|Code))` to find the names of the statutes  \n",
    "\n",
    "I inserted the specific Act in the pattern due to its complexity, and because not many Statutes follow the same pattern.\n",
    "\n",
    "The method first tries to find the possible statutes in the header, failing which, it will look within the judgment text.  \n",
    "\n",
    "The sections and statute names are then extracted and joined to form a final pattern such as `5 Misuse of Drugs Act` in the image above. This pattern is matched within the `statute_crimes` database which I created previously in order to try to find a possible title for the offence.  \n",
    "\n",
    "Where there are multiple sections and statute names found, the method permutates them into all possible combinations to look for matches.\n",
    "\n",
    "All the information is passed as sets at some point in the method to prevent duplicates.\n",
    "\n",
    "If an offence title is found, the possible offence and possible statute is added to a list, and all `possible_offences` and `possible_statutes` are returned as strings in dictionaries.  \n",
    "\n",
    "If no offence title is found, `Unsure` is returned for the possible offence while the `possible_statutes` are returned.  \n",
    "\n",
    "<details>\n",
    "    <summary> <b> Click here for code (Warning: very long code)</b></summary>\n",
    "    \n",
    "```python\n",
    "    def __get_statute(self):\n",
    "        \"\"\"\n",
    "        Identifies criminal offences and statutes mentioned in the judgment based on its header as a first choice, and text as a second choice.\n",
    "        \"\"\"\n",
    "        # Create an empty list of offences\n",
    "        self.__offences = []\n",
    "        \n",
    "        # First try to identify the crimes based on the header of the judgment.\n",
    "        try:\n",
    "            # Search for the header in the html\n",
    "            self.__temp_results1 = self.__search_results.find('p', {'class': 'txt-body'})\n",
    "            self.__temp_results2 = self.__temp_results1.find_all('span')\n",
    "            \n",
    "            # Iterate through the results and try to find the offences\n",
    "            for result in self.__temp_results2:\n",
    "                try:\n",
    "                    # Search for \"Section(s) or \"s(s)\" (abbreviated sections) with digits. First replace weird text.\n",
    "                    section = re.search('([Ss](ection|)(s|) \\d+)', result.text.replace('\\xa0',' ')).group(0).strip()\n",
    "                    \n",
    "                    # Pick out only the section numbers\n",
    "                    section_num = re.sub('([Ss](ection|)(s|) )', \"\", section)\n",
    "                    \n",
    "                    # Pick out patterns which end in Act or Code as these refer to statutes\n",
    "                    statute = re.search(r'((([A-Z][a-z]*)|(Corruption, Drug Trafficking and Other Serious Crimes \\(Confiscation of Benefits\\)|and|of| )){2,}(Act|Code))', result.text.replace('\\xa0',' ')).group(0).strip()\n",
    "                    \n",
    "                    # Combine section numbers and statute\n",
    "                    section_statute = section_num + \" \" + statute\n",
    "                    \n",
    "                    # Checks the database of statutes I created to find a possible offence if it exists within and adds it to the list of offences for this judgment\n",
    "                    if section_statute in self.statutes_df['section_statute'].values:\n",
    "                        index = self.statutes_df[self.statutes_df['section_statute'] == section_statute].index\n",
    "                        offence = self.statutes_df.iloc[index].values\n",
    "                        self.__offences.append([offence[0][1], section_statute])\n",
    "                        \n",
    "                    # If not found within the database of statutes, adds the section number and statute but list offences as \"unsure\"\n",
    "                    else:\n",
    "                        self.__offences.append(['Not in database', section_statute])\n",
    "                        \n",
    "                except:\n",
    "                    pass\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # If the judgment header does not contain the section and statute, identify it through the text\n",
    "        if len(self.__offences) == 0:\n",
    "            print('No offences found in header, checking document text..')\n",
    "            \n",
    "            # Instantiate empty lists\n",
    "            offence_b = []\n",
    "            sections_found = []\n",
    "            statutes_found = []\n",
    "            \n",
    "            # Search for all the document text\n",
    "            self.__search_results2 = self.__search_results.text.replace(\"\\xa0\",\" \")\n",
    "            \n",
    "            # Instantiate empty lists\n",
    "            section_list = []\n",
    "            statute_list = []\n",
    "            try:\n",
    "                # Try to find the sections as above\n",
    "                sections = re.findall('( [Ss](ection|)(s|) \\d+)', self.__search_results2)\n",
    "\n",
    "                # If sections is not empty:\n",
    "                if sections != []:\n",
    "                    # Iterate through the sections and adds their digits to the section list\n",
    "                    for s in sections:\n",
    "                        section_list.append(re.findall(r'\\d+',s[0]))\n",
    "\n",
    "                        # Add the sections found to the list\n",
    "                        for ss in section_list:\n",
    "                            sections_found.append(ss[0])\n",
    "\n",
    "                # Try to find the statutes as above\n",
    "                statutes = re.findall(r'((([A-Z][a-z]*)|(Corruption, Drug Trafficking and Other Serious Crimes \\(Confiscation of Benefits\\)|and|of| )){2,}(Act|Code))', self.__search_results2)\n",
    "\n",
    "                # If statutes is not empty:\n",
    "                if statutes != []:\n",
    "                    # Iterate through the statutes and adds their name to the statute list\n",
    "                    for s in statutes:\n",
    "                        statute_list.append(s[0].strip())\n",
    "\n",
    "                        # Add the statutes found to the list\n",
    "                        for ss in list(statute_list):\n",
    "                            statutes_found.append(ss)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            if statutes_found != []:\n",
    "                # Convert the sections and statutes found to sets to remove duplicates\n",
    "                sections2 = set(sections_found)\n",
    "                statutes2 = set(statutes_found)\n",
    "                \n",
    "                # Permutate through the sections and statutes to find all possible combinations of the two\n",
    "                combinations = list(itertools.product(list(sections2),list(statutes2)))\n",
    "                \n",
    "                # Check if combinations is blank\n",
    "                if combinations == []:\n",
    "                    combinations = list(statutes_found)\n",
    "                \n",
    "                # Instantiate list of possible offences\n",
    "                possible_offences = []\n",
    "                \n",
    "                # Check if combinations has only 1 entry and sets possible_offences as combinations\n",
    "                if type(combinations[0]) == str:\n",
    "                    possible_offences = combinations\n",
    "                \n",
    "                else:\n",
    "                    # Add each possible offence from the permutations to the list of possible offences\n",
    "                    for offence in combinations:\n",
    "                        possible_offences.append(' '.join(offence))\n",
    "                    \n",
    "                # Check the database of statutes I created to find a possible offence if it exists within and adds it to the list of offences for this judgment\n",
    "                for value in possible_offences:\n",
    "                    if value in self.statutes_df['section_statute'].values:\n",
    "                        index = self.statutes_df[self.statutes_df['section_statute'] == value].index\n",
    "                        offence = self.statutes_df.iloc[index].values\n",
    "                        offence_b.append([offence[0][1], value])\n",
    "                        [self.__offences.append(x) for x in offence_b if x not in self.__offences];\n",
    "                        \n",
    "                    # If not found within the database of statutes, adds the section number and statute but list offences as \"unsure\"\n",
    "                    else:\n",
    "                        offence_b.append(['Not in database', value])\n",
    "                        [self.__offences.append(x) for x in offence_b if x not in self.__offences];\n",
    "            \n",
    "        # Instantiate empty lists and dictionaries\n",
    "        self.__title = []\n",
    "        self.__temp_title = []\n",
    "        self.__statute = []\n",
    "        self.__title_statute = {}\n",
    "        \n",
    "        # Iterate through self.__offences\n",
    "        for item in self.__offences:\n",
    "        # Add each offence into temp_title and statute\n",
    "            self.__temp_title.append(item[0])\n",
    "            self.__statute.append(item[1])\n",
    "            \n",
    "        # converts temp_title to a set to remove duplicates\n",
    "        self.__temp_title = set(self.__temp_title)\n",
    "        \n",
    "        # Adds each temp_title to title\n",
    "        for titles in self.__temp_title:\n",
    "            self.__title.append(str(titles))\n",
    "            \n",
    "        # Joins all the titles in title list as a full string\n",
    "        self.__title = \",\".join(self.__title)\n",
    "        \n",
    "        # Joins all the statutes in statute list as a full string\n",
    "        self.__statute = \",\".join(self.__statute)\n",
    "        \n",
    "        # Returns title and statute as a dictionary\n",
    "        self.__title_statute = {'possible_titles': self.__title, 'possible_statutes': self.__statute}\n",
    "        return self.__title_statute\n",
    "        \n",
    "    \n",
    "``` \n",
    "</details>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.6 Other cases cited  \n",
    "\n",
    "For the other cases cited in the judgment, the following pattern was used:  \n",
    "* `Title Case Word` `space` `special name connectors (optional)` or `suffix (optional)` `space` `v` `space` `Title Case Word` `space` `special name connectors (optional)` or `suffix (optional)` (e.g. Syed Suhail bin Syed Zin v Public Prosecutor)  \n",
    "\n",
    "This results in a `regex` expression of `(([A-Z][a-z]*)(([A-Z][a-z]*)|(s\\/o| |bte|bin|and|another|anr|binti|de|the|for|other|matters))* v (([A-Z][a-z]*)|(s\\/o| |bte|bin|and|another|anr|binti|de|the|for|other|matters))*(?=|))`.  \n",
    "\n",
    "A `findall` was used to find all possible matches, and all the matches are iterated through and appended in a list if they are not duplicates.  \n",
    "\n",
    "The `temp_case_name` created previously is now used to remove the judgment's `case_name` from the list of other case `citations`.  \n",
    "\n",
    "Finally, a few outlier captured words are removed and the list is converted to a string to be stored in a dictionary which is returned.  \n",
    "\n",
    "<details>\n",
    "    <summary> <b> Click here for code </b></summary>\n",
    "    \n",
    "```python\n",
    "    def __get_citations(self):\n",
    "        \"\"\"\n",
    "        Searches the document text for case citations which are in the format of `____ v ____`.\n",
    "        \"\"\"\n",
    "        # Replaces weird characters from html and return text\n",
    "        self.__judgment_text = self.__search_results.text.replace('\\xa0','')\n",
    "        \n",
    "        # Searches through text for patterns of Capitalized words with name terms which are followed by v and further capitalized words with name terms as these suggest that it is a case name\n",
    "        self.__case_search = re.findall('(([A-Z][a-z]*)(([A-Z][a-z]*)|(s\\/o| |bte|bin|and|another|anr|binti|de|the|for|other|matters))* v (([A-Z][a-z]*)|(s\\/o| |bte|bin|and|another|anr|binti|de|the|for|other|matters))*(?=|))', self.__judgment_text)\n",
    "        \n",
    "        # Instantiate an empty list\n",
    "        self.__cases = []\n",
    "        \n",
    "        # Iterate through the results to append the case name into a list, excluding duplicates\n",
    "        for item in self.__case_search:\n",
    "            case = []\n",
    "            case.append(re.search('(([A-Z][a-z]*)(([A-Z][a-z]*)|(s\\/o| |bte|bin|and|another|anr|binti|de|the|for|other|matters))* v (([A-Z][a-z]*)|(s\\/o| |bte|bin|and|another|anr|binti|de|the|for|other|matters))*(?=|))', str(item)).group(0).strip().replace(\"In \",\"\"))\n",
    "            [self.__cases.append(x) for x in case if x not in self.__cases];\n",
    "            \n",
    "        # Remove this judgment's name from the list as it cannot be its own citation\n",
    "        self.__cases.remove(self.__temp_case_name)\n",
    "        \n",
    "        # Change the list to a string\n",
    "        self.__cases = \",\".join(self.__cases)\n",
    "        \n",
    "        # Try removing a few wrong words which are captured\n",
    "        try:\n",
    "            self.__cases = self.__cases.replace('Antecedents','').replace('Untraced','').strip()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Returns the citations as a dictionary\n",
    "        self.__citations = {'citations': self.__cases}\n",
    "        return self.__citations   \n",
    "    \n",
    "``` \n",
    "</details>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.7 Mitigating and Aggravating circumstances  \n",
    "\n",
    "To identify whether mitigating and aggravating circumstances were discussed in the judgment, I simply did a search for the words `mitigation`, `mitigation`, `aggravating`, `aggravated` (all case insensitive) in the judgment text and returned `1` if they were found and `0` if they were not.  \n",
    "\n",
    "The purpose of returning it as a binary is so that I can quickly calculate the mean for the statistics by summing them and dividing by the number of rows.  \n",
    "\n",
    "<details>\n",
    "    <summary> <b> Click here for code </b></summary>\n",
    "    \n",
    "```python\n",
    "    def __get_miscellaneous(self):\n",
    "        \"\"\"\n",
    "        Searches the document text to identify if mitigating factors were discussed, and if aggravating factors were discussed\n",
    "        \"\"\"\n",
    "        # Searches the judgment text to see if mitigation or mitigating is mentioned and returns 1 for yes, 0 for no\n",
    "        if re.search(r'[mM]itigation|[mM]itigating',self.__judgment_text):\n",
    "            self.__mitigation_discussed = 1\n",
    "        else:\n",
    "            self.__mitigation_discussed = 0\n",
    "            \n",
    "        # Searches the judgment text to see if aggravating or aggravated is mentioned and returns 1 for yes, 0 for no\n",
    "        if re.search(r'[aA]ggravating|[aA]ggravated',self.__judgment_text):\n",
    "            self.__aggravated_discussed = 1\n",
    "        else:\n",
    "            self.__aggravated_discussed = 0   \n",
    "            \n",
    "        # Returns the results as a dictionary\n",
    "        self.__miscellaneous = {'mitigation_discussed': self.__mitigation_discussed, 'aggravation_discussed': self.__aggravated_discussed}\n",
    "        return self.__miscellaneous   \n",
    "    \n",
    "``` \n",
    "</details>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.8 Database creation and export  \n",
    "\n",
    "For the actual processing of the judgments, the code first identifies which is the relevant court tag, to load the correct dataset of judgments, and sets the relevant start and end indices.  \n",
    "\n",
    "The method then iterates from the start index to the end index, loading each archived html file and parsing it through `BeautifulSoup`. It then calls the various methods above to get the `case_name`, `tribunal/court`, `decision_date`, `possible_offences`, `possible_statutes`, `citations`, `mitigation_discussed`, and `aggravation_discussed`.  \n",
    "\n",
    "At the same time, it also adds a `court_tag`, which identifies whether it is from the `subordinate` or `supreme` court, and `link` from the court links database. These are to allow easy identification of new entries through the number of rows, and linking to the original judgment online as this project will not host any judgments.  \n",
    "\n",
    "The extracted information is merged into a dictionary for each judgment and added to a list of dictionaries, which is finally used to create or merge into the final database.  \n",
    "\n",
    "The final database is then saved as a csv file.  \n",
    "\n",
    "<details>\n",
    "    <summary> <b> Click here for database creation code (Warning: long code) </b></summary>\n",
    "    \n",
    "```python\n",
    "    def __process_judgments(self, court):\n",
    "        \"\"\"\n",
    "        Loads each new html judgment and performs the NLP steps to extract the key information.\n",
    "        \"\"\"\n",
    "        # Instantiate a list for the dictionary outputs of the above functions\n",
    "        self.dictionaries_list = []\n",
    "        \n",
    "        # Set a default start value\n",
    "        self.__start = 0\n",
    "        \n",
    "        # Check which court is being processed, and find the number of new rows to set the start and end indices\n",
    "        if court == 'supreme':\n",
    "            self.__start = self.__supremecourt_rows - self.__new_supremecourt_rows\n",
    "            self.__end = self.__supremecourt_rows\n",
    "        elif court == 'subordinate':\n",
    "            self.__start = self.__subordinatecourt_rows - self.__new_subordinatecourt_rows\n",
    "            self.__end = self.__subordinatecourt_rows\n",
    "            \n",
    "        # Raise an error if an invalid court is set\n",
    "        else:\n",
    "            raise CourtNameError(\"There is only the Subordinate (State) or Supreme Court!\")\n",
    "            \n",
    "        # Load the dataset based on which court is given\n",
    "        self.dataset = pd.read_csv(f'../data/{court}court_compiled.csv')\n",
    "        \n",
    "        # Check if there are any new entries\n",
    "        if self.__start < self.__end:\n",
    "            # Create index range for new entries and iterate through the range of indices\n",
    "            for index in range(self.__start, self.__end):               \n",
    "                # Set the case_link to be the link for the current index\n",
    "                self.__case_link = self.dataset.loc[index]['link']\n",
    "                \n",
    "                # Print the current progress\n",
    "                print(f'Current progress: {index+1}/{self.__end}.')\n",
    "                \n",
    "                # Load the judgment html for the current index and parse it in BeautifulSoup\n",
    "                load_judgment = codecs.open(f'../judgments/{court}_court/{court}court_{index}.html', 'r', 'utf-8')\n",
    "                print('Judgment loaded')\n",
    "                self.document = BeautifulSoup(load_judgment.read())\n",
    "                print('BeautifulSoup initialized')\n",
    "                \n",
    "                # Create __search_results which are the contents of the html\n",
    "                self.__search_results = self.document.find('div', {'class': 'contentsOfFile'})\n",
    "                print('Judgment text identified')\n",
    "                \n",
    "                # Call the functions above to extract the information required\n",
    "                self.__get_case_name()    \n",
    "                print(f'Case name extracted: {self.__case_name}')\n",
    "                self.__get_court()\n",
    "                print(f'Court extracted: {self.__court}')\n",
    "                self.__get_date()       \n",
    "                print(f'Decision date extracted: {self.__decision_date}')\n",
    "                self.__get_statute()   \n",
    "                print(f'Statutes extracted*: {self.__title_statute}')\n",
    "                self.__get_citations()      \n",
    "                print(f'Citations extracted*: {self.__citations}')\n",
    "                self.__get_miscellaneous()\n",
    "                print(f'Miscellaneous extracted*: {self.__miscellaneous}')\n",
    "                \n",
    "                # Add a court_tag column which specifies whether it is subordinate or supreme court (for the identification of new entries)\n",
    "                self.__court_column = {'court_tag': court}\n",
    "                print('tag set')\n",
    "                \n",
    "                # Add the case url\n",
    "                self.__add_link = {'link': self.__case_link}\n",
    "                print('case link set')\n",
    "                \n",
    "                # Create and merge a dictionary which merges all the information extracted for each judgment\n",
    "                self.__dictionaries_merged = self.__case_name.copy()\n",
    "                self.__dictionaries_merged.update(self.__court)\n",
    "                self.__dictionaries_merged.update(self.__decision_date)\n",
    "                self.__dictionaries_merged.update(self.__title_statute)\n",
    "                self.__dictionaries_merged.update(self.__citations)\n",
    "                self.__dictionaries_merged.update(self.__miscellaneous)\n",
    "                self.__dictionaries_merged.update(self.__court_column) \n",
    "                self.__dictionaries_merged.update(self.__add_link)\n",
    "                \n",
    "                # Add the dictionary for each judgment into a list of dictionaries\n",
    "                self.dictionaries_list.append(self.__dictionaries_merged)\n",
    "\n",
    "                # Clear cell output\n",
    "                clear_output(wait=True)\n",
    "            \n",
    "            # Create a Dataframe out of the list of dictionaries\n",
    "            self.database = pd.DataFrame(self.dictionaries_list)\n",
    "            \n",
    "            # Print current progress\n",
    "            print(f'Current progress: DataFrame created.')\n",
    "            \n",
    "            # Merge the Dataframe into the full database\n",
    "            self.database_df = self.database_df.merge(self.database, how='outer')\n",
    "            self.database_df.reset_index(drop=True)\n",
    "            \n",
    "        # Print 'No new entries' if there are no new entries.\n",
    "        else:\n",
    "            self.database = pd.DataFrame()\n",
    "            print('No new entries')   \n",
    "    \n",
    "``` \n",
    "</details>  \n",
    "    \n",
    "    \n",
    "<details>\n",
    "    <summary> <b> Click here for database export code </b></summary>\n",
    "    \n",
    "```python\n",
    "    def __export_database(self):\n",
    "        \"\"\"\n",
    "        Exports dataframes to the respective .csv files\n",
    "        \"\"\"\n",
    "        # Save the temporary database and updated full database to .csv files\n",
    "        self.database.to_csv(path_or_buf=f'../data/database_temp.csv', index=False)\n",
    "        self.database_df.to_csv(path_or_buf=f'../data/database.csv', index=False)   \n",
    "    \n",
    "``` \n",
    "</details>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.9 Public method to perform NLP  \n",
    "\n",
    "Finally, a pipeline method is used to call the functions in order to create or update the database, with a log file created at the end with the latest database update date.  \n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary> <b> Click here for code </b></summary>\n",
    "    \n",
    "```python\n",
    "    def create_database(self,court):\n",
    "        \"\"\"\n",
    "        Call command to pull urls and export to csv database\n",
    "        \"\"\"\n",
    "        # Call the functions to create / update the database\n",
    "        self.__get_num_rows()\n",
    "        self.__process_judgments(court)\n",
    "        self.__export_database()\n",
    "        \n",
    "        # Update the log file for the latest database update date\n",
    "        self.file = open('../logs/database_log.txt', 'a', encoding='utf_8')\n",
    "        self.file.write(f'database last updated on: {datetime.today()}; \\n')\n",
    "        \n",
    "        # Print current progress\n",
    "        print(f'Current progress: Completed judgment processing and export.')   \n",
    "    \n",
    "``` \n",
    "</details>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Testing the custom class\n",
    "\n",
    "### 4.2.1 Libraries Import  \n",
    "\n",
    "I will import the custom class `Database` and pandas to explore the results of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libaries\n",
    "import pandas as pd\n",
    "from criminalcasedatabase import Court, Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Create an instance of the class and run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = Database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current progress: DataFrame created.\n",
      "Current progress: Completed judgment processing and export.\n"
     ]
    }
   ],
   "source": [
    "database.create_database('supreme')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current progress: DataFrame created.\n",
      "Current progress: Completed judgment processing and export.\n"
     ]
    }
   ],
   "source": [
    "database.create_database('subordinate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_name</th>\n",
       "      <th>tribunal/court</th>\n",
       "      <th>decision_date</th>\n",
       "      <th>possible_titles</th>\n",
       "      <th>possible_statutes</th>\n",
       "      <th>citations</th>\n",
       "      <th>mitigation_discussed</th>\n",
       "      <th>aggravation_discussed</th>\n",
       "      <th>court_tag</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chander Kumar a/l Jayagaran v Public Prosecuto...</td>\n",
       "      <td>Court of Appeal</td>\n",
       "      <td>18 January 2021</td>\n",
       "      <td>Punishment for offences,Not in database,Traffi...</td>\n",
       "      <td>394 Misuse of Drugs Act,394 Criminal Procedure...</td>\n",
       "      <td>Perumal v Public Prosecutor and another,Syed S...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>supreme</td>\n",
       "      <td>https://www.lawnet.sg/lawnet/web/lawnet/free-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Public Prosecutor v Teo Ghim Heng [2021] SGHC 13</td>\n",
       "      <td>General Division of the High Court</td>\n",
       "      <td>22 January 2021</td>\n",
       "      <td>Murder,Punishment for culpable homicide not am...</td>\n",
       "      <td>300 Mauritius Dangerous Drugs Act,300 Criminal...</td>\n",
       "      <td>Public Prosecutor v BNO,Osman bin Ali v Public...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>supreme</td>\n",
       "      <td>https://www.lawnet.sg/lawnet/web/lawnet/free-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GCM v Public Prosecutor and another appeal [20...</td>\n",
       "      <td>High Court</td>\n",
       "      <td>25 January 2021</td>\n",
       "      <td>Sale of obscene books, etc.,Not in database,As...</td>\n",
       "      <td>376 Criminal Law Reform Act,376 Films Act,376 ...</td>\n",
       "      <td>Public Prosecutor v GCM,AQW v Public Prosecuto...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>supreme</td>\n",
       "      <td>https://www.lawnet.sg/lawnet/web/lawnet/free-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Public Prosecutor v Salzawiyah bte Latib and o...</td>\n",
       "      <td>General Division of the High Court</td>\n",
       "      <td>26 January 2021</td>\n",
       "      <td>Punishment for offences,Possession and consump...</td>\n",
       "      <td>33 Misuse of Drugs Act,33 Criminal Procedure C...</td>\n",
       "      <td>Joseph v Public Prosecutor,Public Prosecutor v...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>supreme</td>\n",
       "      <td>https://www.lawnet.sg/lawnet/web/lawnet/free-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Public Prosecutor v Salzawiyah bte Latib and o...</td>\n",
       "      <td>General Division of the High Court</td>\n",
       "      <td>26 January 2021</td>\n",
       "      <td>Effacing any writing from a substance bearing ...</td>\n",
       "      <td>261 Misuse of Drugs Act,261 Evidence Act,261 C...</td>\n",
       "      <td>Chai Chien Wei Kelvin v Public Prosecutor,Publ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>supreme</td>\n",
       "      <td>https://www.lawnet.sg/lawnet/web/lawnet/free-r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           case_name  \\\n",
       "0  Chander Kumar a/l Jayagaran v Public Prosecuto...   \n",
       "1   Public Prosecutor v Teo Ghim Heng [2021] SGHC 13   \n",
       "2  GCM v Public Prosecutor and another appeal [20...   \n",
       "3  Public Prosecutor v Salzawiyah bte Latib and o...   \n",
       "4  Public Prosecutor v Salzawiyah bte Latib and o...   \n",
       "\n",
       "                       tribunal/court    decision_date  \\\n",
       "0                     Court of Appeal  18 January 2021   \n",
       "1  General Division of the High Court  22 January 2021   \n",
       "2                          High Court  25 January 2021   \n",
       "3  General Division of the High Court  26 January 2021   \n",
       "4  General Division of the High Court  26 January 2021   \n",
       "\n",
       "                                     possible_titles  \\\n",
       "0  Punishment for offences,Not in database,Traffi...   \n",
       "1  Murder,Punishment for culpable homicide not am...   \n",
       "2  Sale of obscene books, etc.,Not in database,As...   \n",
       "3  Punishment for offences,Possession and consump...   \n",
       "4  Effacing any writing from a substance bearing ...   \n",
       "\n",
       "                                   possible_statutes  \\\n",
       "0  394 Misuse of Drugs Act,394 Criminal Procedure...   \n",
       "1  300 Mauritius Dangerous Drugs Act,300 Criminal...   \n",
       "2  376 Criminal Law Reform Act,376 Films Act,376 ...   \n",
       "3  33 Misuse of Drugs Act,33 Criminal Procedure C...   \n",
       "4  261 Misuse of Drugs Act,261 Evidence Act,261 C...   \n",
       "\n",
       "                                           citations  mitigation_discussed  \\\n",
       "0  Perumal v Public Prosecutor and another,Syed S...                     1   \n",
       "1  Public Prosecutor v BNO,Osman bin Ali v Public...                     0   \n",
       "2  Public Prosecutor v GCM,AQW v Public Prosecuto...                     1   \n",
       "3  Joseph v Public Prosecutor,Public Prosecutor v...                     1   \n",
       "4  Chai Chien Wei Kelvin v Public Prosecutor,Publ...                     0   \n",
       "\n",
       "   aggravation_discussed court_tag  \\\n",
       "0                      0   supreme   \n",
       "1                      0   supreme   \n",
       "2                      1   supreme   \n",
       "3                      1   supreme   \n",
       "4                      0   supreme   \n",
       "\n",
       "                                                link  \n",
       "0  https://www.lawnet.sg/lawnet/web/lawnet/free-r...  \n",
       "1  https://www.lawnet.sg/lawnet/web/lawnet/free-r...  \n",
       "2  https://www.lawnet.sg/lawnet/web/lawnet/free-r...  \n",
       "3  https://www.lawnet.sg/lawnet/web/lawnet/free-r...  \n",
       "4  https://www.lawnet.sg/lawnet/web/lawnet/free-r...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database.database_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 126 entries, 0 to 125\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   case_name              126 non-null    object\n",
      " 1   tribunal/court         126 non-null    object\n",
      " 2   decision_date          126 non-null    object\n",
      " 3   possible_titles        125 non-null    object\n",
      " 4   possible_statutes      125 non-null    object\n",
      " 5   citations              121 non-null    object\n",
      " 6   mitigation_discussed   126 non-null    int64 \n",
      " 7   aggravation_discussed  126 non-null    int64 \n",
      " 8   court_tag              126 non-null    object\n",
      " 9   link                   126 non-null    object\n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 10.0+ KB\n"
     ]
    }
   ],
   "source": [
    "database.database_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_name</th>\n",
       "      <th>tribunal/court</th>\n",
       "      <th>decision_date</th>\n",
       "      <th>possible_titles</th>\n",
       "      <th>possible_statutes</th>\n",
       "      <th>citations</th>\n",
       "      <th>mitigation_discussed</th>\n",
       "      <th>aggravation_discussed</th>\n",
       "      <th>court_tag</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Public Prosecutor v Yak Eng Hwee [2021] SGDC 79</td>\n",
       "      <td>District Court</td>\n",
       "      <td>22 April 2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>subordinate</td>\n",
       "      <td>https://www.lawnet.sg/lawnet/web/lawnet/free-r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           case_name  tribunal/court  \\\n",
       "100  Public Prosecutor v Yak Eng Hwee [2021] SGDC 79  District Court   \n",
       "\n",
       "     decision_date possible_titles possible_statutes citations  \\\n",
       "100  22 April 2021             NaN               NaN       NaN   \n",
       "\n",
       "     mitigation_discussed  aggravation_discussed    court_tag  \\\n",
       "100                     0                      0  subordinate   \n",
       "\n",
       "                                                  link  \n",
       "100  https://www.lawnet.sg/lawnet/web/lawnet/free-r...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database.database_df[database.database_df['possible_titles'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Summary and observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the RBIE system that I created ran well without an errors. It was able to extract information for most judgments accurately, except for a few missing values in the columns `citations`, `possible_offences`, and `possible_statutes`.  \n",
    "\n",
    "However, I checked the judgments with missing `citations` and `possible_statutes`, and found that only the case name was mentioned in those judgments, with no other case citations or statutes found within, hence this is not an issue with the NLP. \n",
    "\n",
    "I manually did a random sample of judgments and found that the accuracy rate for information extraction is close to 100%, although the permutations method causes a lot of non-existent statutes to be listed as `possible_statutes`. This is acceptable as it is more important to reduce type II errors (false negatives) where statutes wich are present are missed out.\n",
    "\n",
    "There are many instances where the `possible_offences` are `Not in database`. This is likely because the NLP uses permutations for statutes which are sometimes found separately from the section number, and the database of `statutes_crimes` is very limited and should be expanded as an improvement to the project.\n",
    "\n",
    "This however, still suggests that the use of RBIE is not perfect, using a brute-force method that causes some wrong data to be captured.   \n",
    "\n",
    "I will not be not dropping any rows despite the null values as the judgments can still be found via their name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] LawNet, a service provided by the Singapore Academy of Law *\"Chander Kumar a/l Jayagaran v Public Prosecutor\n",
    "[2021] SGCA 3,\"* 2021. [Online]. Available: [https://www.lawnet.sg/lawnet/web/lawnet/free-resources?p_p_id=freeresources_WAR_lawnet3baseportlet&p_p_lifecycle=1&p_p_state=normal&p_p_mode=view&p_p_col_id=column-1&p_p_col_pos=2&p_p_col_count=3&_freeresources_WAR_lawnet3baseportlet_action=openContentPage&_freeresources_WAR_lawnet3baseportlet_docId=/Judgment/25538-SSP.xml](https://www.lawnet.sg/lawnet/web/lawnet/free-resources?p_p_id=freeresources_WAR_lawnet3baseportlet&p_p_lifecycle=1&p_p_state=normal&p_p_mode=view&p_p_col_id=column-1&p_p_col_pos=2&p_p_col_count=3&_freeresources_WAR_lawnet3baseportlet_action=openContentPage&_freeresources_WAR_lawnet3baseportlet_docId=/Judgment/25538-SSP.xml) [Accessed: April 6, 2021]."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
